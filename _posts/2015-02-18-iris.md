---
title: "Classification in View: Iris Dataset"
category: ML
date: 2015-02-18
header:
  image: "/images/int1.jpg"
excerpt: "Data Science, Supervised Learning, Unsupervised Learning"
---

## Classification in View: Iris Dataset

### 1. Intouction
Interpreting how a model works is one of the most basic yet critical aspects of data science. You build a model which is giving you pretty impressive results, but what was the process behind it? As a data scientist, you need to have an answer to this often asked questions. This notebook describes the intuitions behind some of the the popular classification models used in datascience today. They include; Logistic regression, support vector machine, Decision trees and some popular Ensemble learning models.  
>> "If you can't explain it simply, you don't understand it well enough".
Albert Einstein

We will be using a simple, yet popular multi-class labeled dataset -Iris, because it is easy to understand, plus it does not need to be cleaned so we can get into the nitty gritty of modelling as soon as possible. You can download the UCI dataset and get a description from [Kaggle.](https://www.kaggle.com/uciml/iris). Without further ado, lets dive in.


```python
#Import important libraries from python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
```


```python
#Load and view iris
iris = pd.read_csv('iris.csv')
iris.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>SepalLengthCm</th>
      <th>SepalWidthCm</th>
      <th>PetalLengthCm</th>
      <th>PetalWidthCm</th>
      <th>Species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2</td>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3</td>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <td>3</td>
      <td>4</td>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <td>4</td>
      <td>5</td>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
  </tbody>
</table>
</div>



**As you can see, there is an 'Id' column that we need to drop from the dataframe.**


```python
iris = iris.drop(['Id'], axis=1)
```


```python
iris.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 150 entries, 0 to 149
    Data columns (total 5 columns):
    SepalLengthCm    150 non-null float64
    SepalWidthCm     150 non-null float64
    PetalLengthCm    150 non-null float64
    PetalWidthCm     150 non-null float64
    Species          150 non-null object
    dtypes: float64(4), object(1)
    memory usage: 6.0+ KB


**There are no null values in the dataset.**


```python
iris.describe() # Describes some statistical composition of the data
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SepalLengthCm</th>
      <th>SepalWidthCm</th>
      <th>PetalLengthCm</th>
      <th>PetalWidthCm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>count</td>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
    </tr>
    <tr>
      <td>mean</td>
      <td>5.843333</td>
      <td>3.054000</td>
      <td>3.758667</td>
      <td>1.198667</td>
    </tr>
    <tr>
      <td>std</td>
      <td>0.828066</td>
      <td>0.433594</td>
      <td>1.764420</td>
      <td>0.763161</td>
    </tr>
    <tr>
      <td>min</td>
      <td>4.300000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>0.100000</td>
    </tr>
    <tr>
      <td>25%</td>
      <td>5.100000</td>
      <td>2.800000</td>
      <td>1.600000</td>
      <td>0.300000</td>
    </tr>
    <tr>
      <td>50%</td>
      <td>5.800000</td>
      <td>3.000000</td>
      <td>4.350000</td>
      <td>1.300000</td>
    </tr>
    <tr>
      <td>75%</td>
      <td>6.400000</td>
      <td>3.300000</td>
      <td>5.100000</td>
      <td>1.800000</td>
    </tr>
    <tr>
      <td>max</td>
      <td>7.900000</td>
      <td>4.400000</td>
      <td>6.900000</td>
      <td>2.500000</td>
    </tr>
  </tbody>
</table>
</div>




```python
iris.Species.value_counts()
```




    Iris-setosa        50
    Iris-versicolor    50
    Iris-virginica     50
    Name: Species, dtype: int64



**We have a perfectly balanced dataset.**
> Check what is meant by inbalanced dataset

### 2. Some Visual Analysis

These colourful plots are gotten from seaborn library. They are also quite easy to use. Just a few line of code and viola! Go through the features at [Seaborn.org](https://seaborn.pydata.org/)


```python
#Boxplots displaying the range (min, quartiles and max) of a distribution.
iris.boxplot(by="Species", figsize=(12, 6))
plt.show()
```


![png](output_13_0.png)



```python
#Pairplots showing all variables paired with all other variables
sns.pairplot(iris,hue='Species')
```




    <seaborn.axisgrid.PairGrid at 0x207503a9c88>




![png](output_14_1.png)



```python
# Distribution plots
iris.hist(edgecolor='black', linewidth=1.2)
fig=plt.gcf()
fig.set_size_inches(12,6)
```


![png](output_15_0.png)


### 3. Pre-Processing


```python
# use sklearn's label encoder to map 'Species' such that Iris-setosa=0, Iris-versicolor=1 and Iris-virginica=2
# next, standardise independent variables especially for models that are sensitive to outliers.

from sklearn.preprocessing import RobustScaler

features = iris.iloc[:, :4]
scaler = RobustScaler()

X = scaler.fit_transform(features)
X[:5]
```




    array([[-0.53846154,  1.        , -0.84285714, -0.73333333],
           [-0.69230769,  0.        , -0.84285714, -0.73333333],
           [-0.84615385,  0.4       , -0.87142857, -0.73333333],
           [-0.92307692,  0.2       , -0.81428571, -0.73333333],
           [-0.61538462,  1.2       , -0.84285714, -0.73333333]])




```python
from sklearn.preprocessing import LabelEncoder

target = iris['Species']
encoder =  LabelEncoder()
y = encoder.fit_transform(target)
y[:5]
```




    array([0, 0, 0, 0, 0])




```python
# Now that we have X and y in good learning states, we can split dataset into train and test.
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
```


```python
X_train.shape, X_test.shape
```




    ((105, 4), (45, 4))



### 4. Model Training

### 4.1. Logistic Regression.
***Perequisite: [Linear Regression](https://meesaan.github.io/enigma.github.io/ml/linear-regression/).***

In a lot of ways, linear regression and logistic regression are similar. However, one major difference is, where linear regression is used to predict continuous values, logistic regression is used for predicting classes. Logistic regression is a classification algorithm that predicts target variables in a Boolean order. That is, it askes the question, is a flower Iris-Setosa or not? Yes or No? True or False? (I am aware I am asking a question of a binary intuition while we have a multiclass dataset. Walk with me, we will address this shortly). Also, unlike linear regression that fits a line to the data, logistic regression fits an 'S' shaped logistic function - also called sigmoid function that can take any real-valued number and map it into a value between 0 and 1 as seen in the diagram below.  
<img src='logistic.png'>
In other words, if the curve goes to positive infinity, y predicted will become 1, and if the curve goes to negative infinity, y predicted will become 0. One thing to note is that, the sigmoid function with formula, <img src='form.png'> is responsible for estimating probabilities that squashes the predicted value into a range of (0, 1) since the numerator is always smaller than the denominator by 1. So far so good up until this point? Good! Now, lets see how a logistic regression model is trained.

This image from [Experfy](https://www.experfy.com/blog/the-logistic-regression-algorithm) below does justice to visualise how logistic regression works.  
<img src='logistic2.png'>

Just like a Linear Regression model, a Logistic Regression model computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the Linear Regression model does, it outputs the probabilities of the collection/sample of flowers given their sepal length, sepal width and so on... Then the sigmoid function groups each flower's probability as a 0 or 1. For example, if the estimated probability that an iris flower-Iris-setosa is greater than 50%, then the model predicts that the flower belongs to that class (called the positive class, labeled “1”) otherwise it predicts that it does not (i.e., it belongs to the negative class, labeled “0”).  If you want to understand the maths of it, you can head on to [Christoph's Page](https://christophm.github.io/interpretable-ml-book/logistic.html). He does a brilliant job at explaining its derivations as simple as possible. Remember how in Linear Regression you estimate the coefficients or weights and bias using ordinary least squares? Well, in Logistic Regression, we estimate the coefficients using Maximum Likelihood Estimation (MLE). The MLE is a "likelihood" maximization method, while OLS is a distance-minimizing approximation method.
Have you noticed that Logistic Regression is a binary classifier yet? However, we have a multinomial classification task at hand. How can we solve this problem with Logistic Regression? One way is to use One-Vs-Rest algorithm. In its learning stage,
Multi class classification is implemented by training multiple logistic regression classifiers, one for each of the K classes (Iris-Setosa, Iris-Versicolor and Iris-Virginica) in the training dataset. When training the classifier for Iris-Setosa, we will treat flowers 1-50 as +ve samples (y==1) and Iris-Versicolor and Iris-Virginica as -ve samples (y==0). When training the classifier for Class 2, we will treat flowers 51-100  as +ve samples (y==1) while Iris-Setosa and Iris-Virginica are treated as -ve samples (y==0). This will continue for all the classes. During prediction, One vs all prediction of the test input, we should compute the “probability” that it belongs to each class using the trained logistic regression classifiers. Your one-vs-rest prediction function will pick the class for which the corresponding logistic regression classifier outputs the highest probability and return the class label (1, 2,..., or K) as the prediction for the input example.
Now that we have a fairly good intuition, we can use scikit-learn for trainin and prediction.


```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

model_log = LogisticRegression(solver='lbfgs', max_iter=500,  multi_class='multinomial', penalty='none')
model_log.fit(X_train, y_train)
```




    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                       intercept_scaling=1, l1_ratio=None, max_iter=500,
                       multi_class='multinomial', n_jobs=None, penalty='none',
                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                       warm_start=False)




```python
predictions = model_log.predict(X_test)

print()# Printing new line

#Check precision, recall, f1-score
print( classification_report(y_test, predictions) )

print( accuracy_score(y_test, predictions))
```

    [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0
     2 1 1 2 0 2 0 0]

                  precision    recall  f1-score   support

               0       1.00      1.00      1.00        16
               1       1.00      0.94      0.97        18
               2       0.92      1.00      0.96        11

        accuracy                           0.98        45
       macro avg       0.97      0.98      0.98        45
    weighted avg       0.98      0.98      0.98        45

    0.9777777777777777



```python
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix
```




    array([[16,  0,  0],
           [ 0, 17,  1],
           [ 0,  0, 11]], dtype=int64)



### 4.2. Support Vector Machhines
A Support Vector Machine (SVM) is a powerful and versatile Machine Learning model, capable of performing linear or nonlinear classification, regression, and even outlier detection. It is one of the most popular models in Machine Learning, and anyone interested in Machine Learning should have it in their toolbox. The fundamental idea behind SVMs is best explained with some
pictures. Figure 5-1 shows part of the iris dataset. The two classes can clearly be separated easily with a straight line (they are linearly separable). The left plot shows the decision boundaries of three possible linear classifiers. The model whose decision boundary is represented by the dashed line is so bad that it does not even separate the classes properly. The other two models work perfectly on this training set, but their decision boundaries come so close to the instances
that these models will probably not perform as well on new instances. In contrast, the solid line in the plot on the right represents the decision boundary of an SVM classifier; this line not only separates the two classes but also stays as far away from the closest training instances as possible. You can think of an SVM classifier as fitting the widest possible street
(represented by the parallel dashed lines) between the classes. This is called large margin classification.  
<img src = 'svm.png'>
Notice that adding more training instances “off the street” will not affect the decision boundary at all: it is fully determined (or “supported”) by the instances located on the edge of the street. These instances are called the support vectors (they are circled in Figure 5-1).  
<img src = 'svm2.png'>
SVMs are sensitive to the feature scales, as you can see in Figure 5-2: in the left plot, the vertical scale is much larger than the horizontal scale, so the widest possible street is close to horizontal. After feature scaling (e.g., using
Scikit-Learn’s StandardScaler), the decision boundary in the right plot looks much better. If we strictly impose that all instances must be off the street and on the right side, this is called hard margin classification. There are two main issues with hard margin classification. First, it only works if the data is linearly separable. Second, it is sensitive to outliers. Figure 5-3 shows the iris dataset with just one additional outlier: on the left, it is impossible to find a hard margin; on the right, the decision boundary ends up very different from the one we saw in Figure 5-1 without the outlier, and it will
probably not generalize as well. To avoid these issues, use a more flexible model. The objective is to find a
good balance between keeping the street as large as possible and limiting the margin violations (i.e., instances that end up in the middle of the street or even on the wrong side). This is called soft margin classification. When creating an SVM model using Scikit-Learn, we can specify a number of hyperparameters. C is one of those hyperparameters. If we set it to a low
value, then we end up with the model on the left of Figure 5-4. With a high value, we get the model on the right. Margin violations are bad. It’s usually better to have few of them. However, in this case the model on the left has a
lot of margin violations but will probably generalize better. If your SVM model is overfitting, you can try regularizing it by reducing C. The following Scikit-Learn code loads the iris dataset, scales the features, and then trains a linear SVM model (using the LinearSVC class with C=1 and the hinge loss function, described shortly) to detect Iris virginica flowers:
import numpy as np
from sklearn import datasets

with SGDClassifier(loss="hinge", alpha=1/(m*C)). This applies regular
Stochastic Gradient Descent (see Chapter 4) to train a linear SVM classifier.
It does not converge as fast as the LinearSVC class, but it can be useful to
handle online classification tasks or huge datasets that do not fit in memory
(out-of-core training).
TIP
The LinearSVC class regularizes the bias term, so you should center the
training set first by subtracting its mean. This is automatic if you scale the
data using the StandardScaler. Also make sure you set
the loss hyperparameter to "hinge", as it is not the default value. Finally, for
better performance, you should set the dual hyperparameter to False,
unless there are more features than training instances (we will discuss
duality later in the chapter).


```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC

svm_clf = Pipeline([
 #("scaler", StandardScaler()),
 ("linear_svc", LinearSVC(max_iter=5000)),
 ])
svm_clf.fit(X_train, y_train)  
```




    Pipeline(memory=None,
             steps=[('linear_svc',
                     LinearSVC(C=1.0, class_weight=None, dual=True,
                               fit_intercept=True, intercept_scaling=1,
                               loss='squared_hinge', max_iter=5000,
                               multi_class='ovr', penalty='l2', random_state=None,
                               tol=0.0001, verbose=0))],
             verbose=False)




```python
svm_predict = svm_clf.predict(X_test)
print( classification_report(y_test, svm_predict) )

print( accuracy_score(y_test, svm_predict))
```

                  precision    recall  f1-score   support

               0       1.00      1.00      1.00        16
               1       0.94      0.89      0.91        18
               2       0.83      0.91      0.87        11

        accuracy                           0.93        45
       macro avg       0.92      0.93      0.93        45
    weighted avg       0.94      0.93      0.93        45

    0.9333333333333333



```python
svm_matrix = metrics.confusion_matrix(y_test, svm_predict)
svm_matrix
```




    array([[16,  0,  0],
           [ 0, 16,  2],
           [ 0,  1, 10]], dtype=int64)



### 3.3 Decision Trees
Like SVMs, Decision Trees are versatile Machine Learning algorithms that can perform both classification and regression tasks, and even multioutput tasks. They are powerful algorithms, capable of fitting complex datasets.  
To understand Decision Trees, let’s build one and take a look at how it
makes predictions. The following code trains a DecisionTreeClassifier on
the iris dataset (see Chapter 4):
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
iris = load_iris()
X = iris.data[:, 2:] # petal length and width
y = iris.target
tree_clf = DecisionTreeClassifier(max_depth=2)
tree_clf.fit(X, y).  

You can visualize the trained Decision Tree by first using
the export_graphviz() method to output a graph definition file
called iris_tree.dot:
from sklearn.tree import export_graphviz
export_graphviz(
 tree_clf,
 out_file=image_path("iris_tree.dot"),
 feature_names=iris.feature_names[2:],
 class_names=iris.target_names,
 rounded=True,
 filled=True
 ).  
 Then you can use the dot command-line tool from the Graphviz package to
convert this .dot file to a variety of formats, such as PDF or PNG.1 This
command line converts the .dot file to a .png image file:
$ dot -Tpng iris_tree.dot -o iris_tree.png .  
Making Predictions
Let’s see how the tree represented in Figure 6-1 makes predictions.
Suppose you find an iris flower and you want to classify it. You start at
the root node (depth 0, at the top): this node asks whether the flower’s
petal length is smaller than 2.45 cm. If it is, then you move down to the
root’s left child node (depth 1, left). In this case, it is a leaf node (i.e., it does
not have any child nodes), so it does not ask any questions: simply look at
the predicted class for that node, and the Decision Tree predicts that your
flower is an Iris setosa (class=setosa).
Now suppose you find another flower, and this time the petal length is
greater than 2.45 cm. You must move down to the root’s right child node
(depth 1, right), which is not a leaf node, so the node asks another question:
is the petal width smaller than 1.75 cm? If it is, then your flower is most
likely an Iris versicolor (depth 2, left). If not, it is likely an Iris
virginica (depth 2, right). It’s really that simple.  
A node’s samples attribute counts how many training instances it applies to.
For example, 100 training instances have a petal length greater than 2.45
cm (depth 1, right), and of those 100, 54 have a petal width smaller than
1.75 cm (depth 2, left). A node’s value attribute tells you how many training
instances of each class this node applies to: for example, the bottom-right
node applies to 0 Iris setosa, 1 Iris versicolor, and 45 Iris virginica. Finally, a
node’s gini attribute measures its impurity: a node is “pure” (gini=0) if all
training instances it applies to belong to the same class. For example, since
the depth-1 left node applies only to Iris setosa training instances, it is pure
and its gini score is 0. Equation 6-1 shows how the training algorithm
computes the gini score Gi of the i
th node. The depth-2 left node has
a gini score equal to 1 – (0/54)2 – (49/54)2 – (5/54)2 ≈ 0.168.
Equation 6-1. Gini impurity
Gi=1−∑k=1npi,k2Gi=1-∑k=1npi,k2
In this equation:
• pi,k is the ratio of class k instances among the training instances in
the i
th node.
NOTE
Scikit-Learn uses the CART algorithm, which produces only binary trees:
nonleaf nodes always have two children (i.e., questions only have yes/no
answers). However, other algorithms such as ID3 can produce Decision
Trees with nodes that have more than two children.  
Scikit-Learn uses the Classification and Regression Tree (CART) algorithm to
train Decision Trees (also called “growing” trees). The algorithm works by
first splitting the training set into two subsets using a single feature k and a
threshold tk (e.g., “petal length ≤ 2.45 cm”). How does it choose k and tk? It
searches for the pair (k, tk) that produces the purest subsets (weighted by
their size). Equation 6-2 gives the cost function that the algorithm tries to
minimize.  
As you can see, the CART algorithm is a greedy algorithm: it greedily
searches for an optimum split at the top level, then repeats the process at
each subsequent level. It does not check whether or not the split will lead
to the lowest possible impurity several levels down. A greedy algorithm
often produces a solution that’s reasonably good but not guaranteed to be
optimal.
Unfortunately, finding the optimal tree is known to be an NPComplete problem:2 it requires O(exp(m)) time, making the problem
intractable even for small training sets. This is why we must settle for a
“reasonably good” solution.  
To avoid overfitting the training data, you need to restrict the Decision
Tree’s freedom during training. As you know by now, this is called
regularization. The regularization hyperparameters depend on the
algorithm used, but generally you can at least restrict the maximum depth
of the Decision Tree. In Scikit-Learn, this is controlled by
the max_depth hyperparameter (the default value is None, which means
unlimited). Reducing max_depth will regularize the model and thus reduce
the risk of overfitting.
The DecisionTreeClassifier class has a few other parameters that similarly
restrict the shape of the Decision Tree: min_samples_split (the minimum
number of samples a node must have before it can be
split), min_samples_leaf (the minimum number of samples a leaf node must
have), min_weight_fraction_leaf (same as min_samples_leaf but expressed as
a fraction of the total number of weighted instances), max_leaf_nodes (the
maximum number of leaf nodes), and max_features (the maximum number
of features that are evaluated for splitting at each node).
Increasing min_* hyperparameters or reducing max_* hyperparameters will
regularize the model.  

### 3.4. Ensemble Methods
Suppose you pose a complex question to thousands of random people, then aggregate their answers. In many cases you will find that this aggregated answer is better than an expert’s answer. This is called the wisdom of the crowd. Similarly, if you aggregate the predictions of a group of predictors (such as classifiers or regressors), you will often get better predictions than with the best individual predictor. A group of predictors is called an ensemble; thus, this technique is called Ensemble Learning, and an Ensemble Learning algorithm is called an Ensemble method.  
Let's take a real example to build the intuition.

Suppose, you want to invest in a company XYZ. You are not sure about its performance though. So, you look for advice on whether the stock price will increase by more than 6% per annum or not? You decide to approach various experts having diverse domain experience.  
An ensemble is the art of combining a diverse set of learners (individual models) together to improvise on the stability and predictive power of the model. In the above example, the way we combine all the predictions collectively will be termed as Ensemble learning.  
As an example of an Ensemble method, you can train a group of Decision Tree classifiers, each on a different random subset of the training set. To make predictions, you obtain the predictions of all the individual trees, then predict the class that gets the most votes (see the last exercise in Chapter 6). Such an ensemble of Decision Trees is called a Random Forest, and despite its
simplicity, this is one of the most powerful Machine Learning algorithms available today.

### 3.4.1. Voting Classifiers
Suppose you have trained a few classifiers, each one achieving about 80% accuracy. You may have a Logistic Regression classifier, an SVM classifier, a Random Forest classifier, a K-Nearest Neighbors classifier, and perhaps a few more (see Figure 7-1).  
A very simple way to create an even better classifier is to aggregate the predictions of each classifier and predict the class that gets the most votes. This majority-vote classifier is called a hard voting classifier (see Figure 7-.  
Similarly, suppose you build an ensemble containing 1,000 classifiers that are individually correct only 51% of the time (barely better than random guessing). If you predict the majority voted class, you can hope for up to 75% accuracy! However, this is only true if all classifiers are perfectly independent, making uncorrelated errors, which is clearly not the case because they are trained on the same data. They are likely to make the same types of errors, so there will be many majority votes for the wrong class, reducing the ensemble’s accuracy. TIP Ensemble methods work best when the predictors are as independent from one another as possible. One way to get diverse classifiers is to train them
using very different algorithms. This increases the chance that they will make very different types of errors, improving the ensemble’s accuracy.  
The following code creates and trains a voting classifier in Scikit-Learn,
composed of three diverse classifiers (the training set is the moons dataset,
introduced in Chapter 5):
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
log_clf = LogisticRegression()
rnd_clf = RandomForestClassifier()
svm_clf = SVC()
voting_clf = VotingClassifier(
 estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],
 voting='hard')
voting_clf.fit(X_train, y_train)
Let’s look at each classifier’s accuracy on the test set:
>>> from sklearn.metrics import accuracy_score
>>> for clf in (log_clf, rnd_clf, svm_clf, voting_clf):
... clf.fit(X_train, y_train)
... y_pred = clf.predict(X_test)
... print(clf.__class__.__name__, accuracy_score(y_test, y_pred))
...
LogisticRegression 0.864
RandomForestClassifier 0.896
SVC 0.888
VotingClassifier 0.904

### 3.4.2. Bagging Classifiers
One way to get a diverse set of classifiers is to use very different training algorithms, as just discussed. Another approach is to use the same training algorithm for every predictor and train them on different random subsets of the training set. When sampling is performed with replacement, this method is called bagging1 (short for bootstrap aggregating2). When sampling is performed without replacement, it is called pasting.3 In other words, both bagging and pasting allow training instances to be sampled several times across multiple predictors, but only bagging allows
training instances to be sampled several times for the same predictor. This sampling and training process is represented in Figure 7-4.  
Bagging is one of the Ensemble construction techniques which is also known as Bootstrap Aggregation. Bootstrap establishes the foundation of Bagging technique. Bootstrap is a sampling technique in which we select “n” observations out of a population of “n” observations. But the selection is entirely random, i.e., each observation can be chosen from the original population so that each observation is equally likely to be selected in each iteration of the bootstrapping process. After the bootstrapped samples are formed, separate models are trained with the bootstrapped samples. In real experiments, the bootstrapped samples are drawn from the training set, and the sub-models are tested using the testing set. The final output prediction is combined across the projections of all the sub-models.  
<img src= 'bagging.png'> [Source](https://hudsonthames.org/bagging-in-financial-machine-learning-sequential-bootstrapping-python/)
Once all predictors are trained, the ensemble can make a prediction for a new instance by simply aggregating the predictions of all predictors. The aggregation function is typically the statistical mode (i.e., the most frequent prediction, just like a hard voting classifier) for classification, or the average for regression. Each individual predictor has a higher bias than if it
were trained on the original training set, but aggregation reduces both bias and variance.4 Generally, the net result is that the ensemble has a similar bias but a lower variance than a single predictor trained on the original training set.
Bagging and Pasting in Scikit-Learn
Scikit-Learn offers a simple API for both bagging and pasting with
the BaggingClassifier class (or BaggingRegressor for regression). The
following code trains an ensemble of 500 Decision Tree classifiers:5 each is
trained on 100 training instances randomly sampled from the training set
with replacement (this is an example of bagging, but if you want to use
pasting instead, just set bootstrap=False). The n_jobs parameter tells ScikitLearn the number of CPU cores to use for training and predictions (–1 tells
Scikit-Learn to use all available cores):
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
bag_clf = BaggingClassifier(
 DecisionTreeClassifier(), n_estimators=500,
 max_samples=100, bootstrap=True, n_jobs=-1)
bag_clf.fit(X_train, y_train)
y_pred = bag_clf.predict(X_test)
NOTE
The BaggingClassifier automatically performs soft voting instead of hard
voting if the base classifier can estimate class probabilities (i.e., if it has
a predict_proba() method), which is the case with Decision Tree classifiers.

### 3.4.3. Random Forests
As we have discussed, a Random Forest9 is an ensemble of Decision Trees,
generally trained via the bagging method (or sometimes pasting), typically
with max_samples set to the size of the training set. Instead of building
a BaggingClassifier and passing it a DecisionTreeClassifier, you can instead
use the RandomForestClassifier class, which is more convenient and
optimized for Decision Trees10 (similarly, there is
a RandomForestRegressor class for regression tasks). The following code uses
all available CPU cores to train a Random Forest classifier with 500 trees
(each limited to maximum 16 nodes):
from sklearn.ensemble import RandomForestClassifier
rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16,
n_jobs=-1)
rnd_clf.fit(X_train, y_train)
y_pred_rf = rnd_clf.predict(X_test)
With a few exceptions, a RandomForestClassifier has all the hyperparameters
of a DecisionTreeClassifier (to control how trees are grown), plus all the
hyperparameters of a BaggingClassifier to control the ensemble itself.11
The Random Forest algorithm introduces extra randomness when growing
trees; instead of searching for the very best feature when splitting a node
(see Chapter 6), it searches for the best feature among a random subset of
features. The algorithm results in greater tree diversity, which (again)
trades a higher bias for a lower variance, generally yielding an overall
better model. The following BaggingClassifier is roughly equivalent to the
previous RandomForestClassifier:
bag_clf = BaggingClassifier(
 DecisionTreeClassifier(splitter="random", max_leaf_nodes=16),
 n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)
Extra-Trees
When you are growing a tree in a Random Forest, at each node only a
random subset of the features is considered for splitting (as discussed
earlier). It is possible to make trees even more random by also using
random thresholds for each feature rather than searching for the best
possible thresholds (like regular Decision Trees do).
A forest of such extremely random trees is called an Extremely Randomized
Trees ensemble12 (or Extra-Trees for short). Once again, this technique
trades more bias for a lower variance. It also makes Extra-Trees much
faster to train than regular Random Forests, because finding the best
possible threshold for each feature at every node is one of the most timeconsuming tasks of growing a tree.
You can create an Extra-Trees classifier using ScikitLearn’s ExtraTreesClassifier class. Its API is identical to
the RandomForestClassifier class. Similarly, the ExtraTreesRegressor class has
the same API as the RandomForestRegressor class.
TIP
It is hard to tell in advance whether a RandomForestClassifier will perform
better or worse than an ExtraTreesClassifier. Generally, the only way to
know is to try both and compare them using cross-validation (tuning the
hyperparameters using grid search).
Feature Importance
Yet another great quality of Random Forests is that they make it easy to
measure the relative importance of each feature. Scikit-Learn measures a
feature’s importance by looking at how much the tree nodes that use that
feature reduce impurity on average (across all trees in the forest). More
precisely, it is a weighted average, where each node’s weight is equal to the
number of training samples that are associated with it (see Chapter 6).
Scikit-Learn computes this score automatically for each feature after
training, then it scales the results so that the sum of all importances is
equal to 1. You can access the result using the feature_importances_ variable.
For example, the following code trains a RandomForestClassifier on the iris
dataset (introduced in Chapter 4) and outputs each feature’s importance. It
seems that the most important features are the petal length (44%) and width (42%), while sepal length and width are rather unimportant in
comparison (11% and 2%, respectively):
>>> from sklearn.datasets import load_iris
>>> iris = load_iris()
>>> rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)
>>> rnd_clf.fit(iris["data"], iris["target"])
>>> for name, score in zip(iris["feature_names"],
rnd_clf.feature_importances_):
... print(name, score)
...
sepal length (cm) 0.112492250999
sepal width (cm) 0.0231192882825
petal length (cm) 0.441030464364
petal width (cm) 0.423357996355


### 3.5. Boosting
Boosting (originally called hypothesis boosting) refers to any Ensemble
method that can combine several weak learners into a strong learner. The
general idea of most boosting methods is to train predictors sequentially,
each trying to correct its predecessor. There are many boosting methods
available, but by far the most popular are AdaBoost13 (short for Adaptive
Boosting) and Gradient Boosting. Let’s start with AdaBoost.  


### 3.5.1. AdaBoost
One way for a new predictor to correct its predecessor is to pay a bit more
attention to the training instances that the predecessor underfitted. This
results in new predictors focusing more and more on the hard cases. This is
the technique used by AdaBoost.
For example, when training an AdaBoost classifier, the algorithm first
trains a base classifier (such as a Decision Tree) and uses it to make
predictions on the training set. The algorithm then increases the relative
weight of misclassified training instances. Then it trains a second classifier,
using the updated weights, and again makes predictions on the training set,
updates the instance weights, and so on (see Figure 7-7).  
Let’s take a closer look at the AdaBoost algorithm. Each instance
weight w(
i
) is initially set to 1/m. A first predictor is trained, and its
weighted error rate r1 is computed on the training set; see Equation 7-1.  
The predictor’s weight αj is then computed using Equation 7-2, where η is
the learning rate hyperparameter (defaults to 1).15 The more accurate the
predictor is, the higher its weight will be. If it is just guessing randomly,
then its weight will be close to zero. However, if it is most often wrong (i.e.,
less accurate than random guessing), then its weight will be negative.  
Next, the AdaBoost algorithm updates the instance weights, using Equation
7-3, which boosts the weights of the misclassified instances.  
Finally, a new predictor is trained using the updated weights, and the
whole process is repeated (the new predictor’s weight is computed, the
instance weights are updated, then another predictor is trained, and so on).
The algorithm stops when the desired number of predictors is reached, or
when a perfect predictor is found.
To make predictions, AdaBoost simply computes the predictions of all the
predictors and weighs them using the predictor weights αj. The predicted
class is the one that receives the majority of weighted votes (see Equation.  
Scikit-Learn uses a multiclass version of AdaBoost called SAMME16 (which
stands for Stagewise Additive Modeling using a Multiclass Exponential loss
function). When there are just two classes, SAMME is equivalent to AdaBoost. If the predictors can estimate class probabilities (i.e., if they have
a predict_proba() method), Scikit-Learn can use a variant of SAMME
called SAMME.R (the R stands for “Real”), which relies on class probabilities
rather than predictions and generally performs better.
The following code trains an AdaBoost classifier based on 200 Decision
Stumps using Scikit-Learn’s AdaBoostClassifier class (as you might expect,
there is also an AdaBoostRegressor class). A Decision Stump is a Decision Tree
with max_depth=1—in other words, a tree composed of a single decision
node plus two leaf nodes. This is the default base estimator for
the AdaBoostClassifier class:
from sklearn.ensemble import AdaBoostClassifier
ada_clf = AdaBoostClassifier(
 DecisionTreeClassifier(max_depth=1), n_estimators=200,
 algorithm="SAMME.R", learning_rate=0.5)
ada_clf.fit(X_train, y_train)
TIP
If your AdaBoost ensemble is overfitting the training set, you can try
reducing the number of estimators or more strongly regularizing the base
estimator.


### Gradient Boosting
Another very popular boosting algorithm is Gradient Boosting.17 Just like
AdaBoost, Gradient Boosting works by sequentially adding predictors to an
ensemble, each one correcting its predecessor. However, instead of
tweaking the instance weights at every iteration like AdaBoost does, this
method tries to fit the new predictor to the residual errors made by the
previous predictor.
Let’s go through a simple regression example, using Decision Trees as the
base predictors (of course, Gradient Boosting also works great with
regression tasks). This is called Gradient Tree Boosting, or Gradient Boosted
Regression Trees (GBRT). First, let’s fit a DecisionTreeRegressor to the
training set (for example, a noisy quadratic training set).  
from sklearn.tree import DecisionTreeRegressor
tree_reg1 = DecisionTreeRegressor(max_depth=2)
tree_reg1.fit(X, y)
Next, we’ll train a second DecisionTreeRegressor on the residual errors made
by the first predictor:
y2 = y - tree_reg1.predict(X)
tree_reg2 = DecisionTreeRegressor(max_depth=2)
tree_reg2.fit(X, y2)
Then we train a third regressor on the residual errors made by the second
predictor:
y3 = y2 - tree_reg2.predict(X)
tree_reg3 = DecisionTreeRegressor(max_depth=2)
tree_reg3.fit(X, y3)
Now we have an ensemble containing three trees. It can make predictions
on a new instance simply by adding up the predictions of all the trees:
y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2,
tree_reg3))
Figure 7-9 represents the predictions of these three trees in the left
column, and the ensemble’s predictions in the right column. In the first
row, the ensemble has just one tree, so its predictions are exactly the same
as the first tree’s predictions. In the second row, a new tree is trained on
the residual errors of the first tree. On the right you can see that the
ensemble’s predictions are equal to the sum of the predictions of the first
two trees. Similarly, in the third row another tree is trained on the residual
errors of the second tree. You can see that the ensemble’s predictions
gradually get better as trees are added to the ensemble.
A simpler way to train GBRT ensembles is to use ScikitLearn’s GradientBoostingRegressor class. Much like
the RandomForestRegressor class, it has hyperparameters to control the
growth of Decision Trees (e.g., max_depth, min_samples_leaf), as well as
hyperparameters to control the ensemble training, such as the number of
trees (n_estimators). The following code creates the same ensemble as the
previous one


```python

```
